{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, hooks, launch\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\n",
    "    \"phone_train\",\n",
    "    {},\n",
    "    \"data/phone/annotations/train.json\",\n",
    "    \"data/phone/train\"\n",
    ")\n",
    "register_coco_instances(\n",
    "    \"phone_val\",\n",
    "    {},\n",
    "    \"data/phone/annotations/val.json\",\n",
    "    \"data/phone/val\"\n",
    ")\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"phone.yaml\")\n",
    "cfg.MODEL.WEIGHTS = \"output/model_final.pth\"\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"phone_val\")\n",
    "meta = MetadataCatalog.get(\"phone_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4\n",
    "predictor = DefaultPredictor(cfg)\n",
    "for d in random.sample(dataset_dicts, 10):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    out = predictor(img)\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=meta, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    visimg = vis.get_image()[:, :, ::-1]\n",
    "    # 添加这一行\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=meta, scale=0.5)\n",
    "    pre = visualizer.draw_instance_predictions(out[\"instances\"].to(\"cpu\"))\n",
    "    preimg = pre.get_image()[:, :, ::-1]\n",
    "    \n",
    "    plt.figure()\n",
    "    img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)\n",
    "    imgs = numpy.stack((img, visimg, preimg))\n",
    "    imgs = imgs.transpose((0,3,1,2))\n",
    "    imgs = torch.from_numpy(imgs)\n",
    "    imgs = torchvision.utils.make_grid(imgs).numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xa = []\n",
    "cra = []\n",
    "fpra = []\n",
    "fnra = []\n",
    "\n",
    "minidata = dataset_dicts\n",
    "\n",
    "for th in numpy.arange(0.1, 0.95, 0.1):\n",
    "    total = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = float(th)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "    for d in minidata:\n",
    "        img = cv2.imread(d[\"file_name\"])\n",
    "        out = predictor(img)\n",
    "        t=len(d['annotations']) == 0\n",
    "        y=len(out[\"instances\"]) == 0\n",
    "        if t == y == True:\n",
    "            tp += 1\n",
    "        elif t == y == False:\n",
    "            tn += 1\n",
    "        elif t == True:\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        total += 1\n",
    "        \n",
    "    cr = (tp+tn)/total\n",
    "    fpr = fp/(fp+tn)\n",
    "    fnr = fn/(fn+tp)\n",
    "    \n",
    "    print(\"thre: %.2f, correct: %.2f, fpr: %.2f, fnr: %.2f\" % (th, cr, fpr, fnr))\n",
    "    \n",
    "    xa.append(th)\n",
    "    cra.append(cr)\n",
    "    fpra.append(fpr)\n",
    "    fnra.append(fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(xa,cra,label='Precision ')\n",
    "plt.plot(xa,fpra,label='FPR')\n",
    "plt.plot(xa,fnra,label='FNR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}